{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "import einops as E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yijing/workspace/torch_cache/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dinov2.models.vision_transformer.DinoVisionTransformer'>\n",
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_intermediate_layers_chunked', '_get_intermediate_layers_not_chunked', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'blocks', 'buffers', 'call_super_init', 'children', 'chunked_blocks', 'cls_token', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'embed_dim', 'eval', 'extra_repr', 'float', 'forward', 'forward_features', 'forward_features_list', 'get_buffer', 'get_extra_state', 'get_intermediate_layers', 'get_parameter', 'get_submodule', 'half', 'head', 'init_weights', 'interpolate_antialias', 'interpolate_offset', 'interpolate_pos_encoding', 'ipu', 'load_state_dict', 'mask_token', 'modules', 'mtia', 'n_blocks', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'norm', 'num_features', 'num_heads', 'num_register_tokens', 'num_tokens', 'parameters', 'patch_embed', 'patch_size', 'pos_embed', 'prepare_tokens_with_masks', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'register_tokens', 'requires_grad_', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n",
      "Padded shape: torch.Size([1, 3, 518, 518])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "x.shape:  torch.Size([1, 1370, 384])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n",
      "cls_tok.shape:  torch.Size([1, 384])\n",
      "x_i.shape:  torch.Size([1, 384, 37, 37])\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_output(output_type, dense_tokens, cls_token, feat_hw):\n",
    "    if output_type == \"cls\":\n",
    "        assert cls_token is not None\n",
    "        output = cls_token\n",
    "    elif output_type == \"gap\":\n",
    "        output = dense_tokens.mean(dim=1)\n",
    "    elif output_type == \"dense\":\n",
    "        h, w = feat_hw\n",
    "        dense_tokens = E.rearrange(dense_tokens, \"b (h w) c -> b c h w\", h=h, w=w)\n",
    "        output = dense_tokens.contiguous()\n",
    "    elif output_type == \"dense-cls\":\n",
    "        assert cls_token is not None\n",
    "        h, w = feat_hw\n",
    "        dense_tokens = E.rearrange(dense_tokens, \"b (h w) c -> b c h w\", h=h, w=w)\n",
    "        cls_token = cls_token[:, :, None, None].repeat(1, 1, h, w)\n",
    "        output = torch.cat((dense_tokens, cls_token), dim=1).contiguous()\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    return output\n",
    "    \n",
    "\n",
    "def debug_forward():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # 创建模拟输入\n",
    "    x = torch.randn(1, 3, 512, 512).to(device)\n",
    "\n",
    "    torch.hub.set_dir('/home/yijing/workspace/torch_cache')\n",
    "    # 加载模型\n",
    "    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device)\n",
    "    print(type(model))\n",
    "    print(dir(model))\n",
    "\n",
    "    # 模拟 center_padding\n",
    "    def mock_center_padding(x):\n",
    "        _, _, h, w = x.shape\n",
    "        pad_h = (14 - h % 14) % 14\n",
    "        pad_w = (14 - w % 14) % 14\n",
    "        \n",
    "        pad_t = pad_h // 2\n",
    "        pad_b = pad_h - pad_t\n",
    "        pad_l = pad_w // 2\n",
    "        pad_r = pad_w - pad_l\n",
    "         \n",
    "        return F.pad(x, (pad_l, pad_r, pad_t, pad_b))\n",
    "    \n",
    "    # 模拟填充\n",
    "    x_padded = mock_center_padding(x)\n",
    "    print('Padded shape:', x_padded.shape)\n",
    "    x = model.prepare_tokens_with_masks(x_padded, None)\n",
    "    embeds = []\n",
    "    for i, blk in enumerate(model.blocks):\n",
    "        x = blk(x)\n",
    "        print('x.shape: ', x.shape)\n",
    "        embeds.append(x)\n",
    "\n",
    "    num_spatial = 37 * 37\n",
    "    outputs = []\n",
    "    for i, x_i in enumerate(embeds):\n",
    "        cls_tok = x_i[:, 0]\n",
    "        print('cls_tok.shape: ', cls_tok.shape)\n",
    "        # ignoring register tokens\n",
    "        spatial = x_i[:, -1 * num_spatial :]\n",
    "        h, w = 37, 37\n",
    "        x_i = tokens_to_output(\"dense\", spatial, cls_tok, (h, w))\n",
    "        print('x_i.shape: ', x_i.shape)\n",
    "        outputs.append(x_i)\n",
    "\n",
    "# 运行调试\n",
    "debug_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yijing/workspace/torch_cache/mhamilton723_FeatUp_main\n",
      "Using cache found in /home/yijing/workspace/torch_cache/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape: torch.Size([1, 3, 518, 518])\n",
      "Feature shape: torch.Size([1, 384, 592, 592])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yijing/.conda/envs/boosting3DOF/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# def debug_forward():\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     # 创建模拟输入\n",
    "#     x = torch.randn(1, 3, 512, 512).to(device)\n",
    "\n",
    "#     torch.hub.set_dir('/home/yijing/workspace/torch_cache')\n",
    "#     # 加载模型\n",
    "#     model = torch.hub.load(\"mhamilton723/FeatUp\", 'dinov2', trust_repo=True).to(device)\n",
    "\n",
    "#     # 模拟 center_padding\n",
    "#     def mock_center_padding(x):\n",
    "#         _, _, h, w = x.shape\n",
    "#         pad_h = (14 - h % 14) % 14\n",
    "#         pad_w = (14 - w % 14) % 14\n",
    "        \n",
    "#         pad_t = pad_h // 2\n",
    "#         pad_b = pad_h - pad_t\n",
    "#         pad_l = pad_w // 2\n",
    "#         pad_r = pad_w - pad_l\n",
    "        \n",
    "#         return F.pad(x, (pad_l, pad_r, pad_t, pad_b))\n",
    "    \n",
    "#     # 模拟填充\n",
    "#     x_padded = mock_center_padding(x)\n",
    "#     print('Padded shape:', x_padded.shape)\n",
    "    \n",
    "#     # 前向传播\n",
    "#     feat = model(x_padded)\n",
    "#     print('Feature shape:', feat.shape)\n",
    "\n",
    "# # 运行调试\n",
    "# debug_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/yijing/.conda/envs/boosting3DOF/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
    "  warn(f\"Failed to load image Python extension: {e}\")\n",
    "Using cache found in /home/yijing/workspace/torch_cache/mhamilton723_FeatUp_main\n",
    "Using cache found in /home/yijing/workspace/torch_cache/facebookresearch_dinov2_main\n",
    "Padded shape: torch.Size([1, 3, 518, 518])\n",
    "Feature shape: torch.Size([1, 384, 592, 592])\n",
    "/home/yijing/.conda/envs/boosting3DOF/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
    "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boosting3DOF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
